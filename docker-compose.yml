services:
  # ============================
  # 1) Zookeeper
  # ============================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - cdc-net
    restart: unless-stopped

  # ============================
  # 2) Kafka Broker
  # ============================
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    networks:
      - cdc-net
    restart: unless-stopped

  # ============================
  # 3) Kafka Connect + Debezium
  # ============================
  connect:
    image: debezium/connect:2.4
    container_name: connect
    depends_on:
      - kafka
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: my_connect_configs
      OFFSET_STORAGE_TOPIC: my_connect_offsets
      STATUS_STORAGE_TOPIC: my_connect_statuses

      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMAS_ENABLE: "true"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "true"

      CONFIG_STORAGE_REPLICATION_FACTOR: 1
      OFFSET_STORAGE_REPLICATION_FACTOR: 1
      STATUS_STORAGE_REPLICATION_FACTOR: 1

      REST_ADVERTISED_HOST_NAME: connect
      REST_PORT: 8083

      # يسمح بموديولات Debezium الإضافية
      ENABLE_DEBEZIUM_SCRIPTING: "true"
    volumes:
      - ./connectors:/kafka/connectors
    networks:
      - cdc-net
    restart: unless-stopped

  # ============================
  # 4) HDFS (NameNode + DataNode)
  #    Images من Big Data Europe
  #    (Hadoop + HDFS جاهزين للدراسة) :contentReference[oaicite:3]{index=3}
  # ============================
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    environment:
      - CLUSTER_NAME=cdc-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=1
    ports:
      - "9870:9870"   # NameNode UI
      - "9000:9000"   # HDFS RPC
    volumes:
      - namenode_data:/hadoop/dfs/name
    networks:
      - cdc-net
    restart: unless-stopped

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    depends_on:
      - namenode
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=1
      - SERVICE_PRECONDITION=namenode:9870
    ports:
      - "9864:9864"   # DataNode UI
    volumes:
      - datanode_data:/hadoop/dfs/data
    networks:
      - cdc-net
    restart: unless-stopped

  # ============================
  # 5) Hive Metastore (PostgreSQL + Service)
  #    Setup مبني على docker-hive من BDE2020 :contentReference[oaicite:4]{index=4}
  # ============================
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    container_name: hive-metastore-postgresql
    volumes:
      - metastore_db:/var/lib/postgresql/data
    networks:
      - cdc-net
    restart: unless-stopped

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    depends_on:
      - namenode
      - datanode
      - hive-metastore-postgresql
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 hive-metastore-postgresql:5432"
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore-postgresql/metastore"
    volumes:
      - ./hive-site.xml:/opt/hive/conf/hive-site.xml
    ports:
      - "9083:9083"
    networks:
      - cdc-net
    restart: unless-stopped

  # ============================
  # 6) HiveServer2
  # ============================
  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    depends_on:
      - hive-metastore
      - namenode
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore-postgresql/metastore"
      CORE_CONF_fs_defaultFS: "hdfs://namenode:9000"
      SERVICE_PRECONDITION: "hive-metastore:9083 namenode:9870"
    volumes:
      - ./hive-site.xml:/opt/hive/conf/hive-site.xml
    ports:
      - "10000:10000"    # Beeline / JDBC
    networks:
      - cdc-net
    restart: unless-stopped

  # ============================
  # 7) Spark Cluster (Master + Worker)
  #    Images من BDE2020 docker-spark :contentReference[oaicite:5]{index=5}
  # ============================
  spark-master:
    image: bde2020/spark-master:3.1.2-hadoop3.2
    container_name: spark-master
    depends_on:
      - namenode
      - datanode
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    ports:
      - "7077:7077"   # Spark master
      - "8080:8080"   # Spark master UI
    volumes:
      - spark_app:/opt/spark-app
      - spark_data:/tmp/spark-events
    networks:
      - cdc-net
    restart: unless-stopped

  spark-worker-1:
    image: bde2020/spark-worker:3.1.2-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    ports:
      - "8081:8081"   # Spark worker UI
    networks:
      - cdc-net
    restart: unless-stopped

  # ============================
  # 8) Kafdrop (Kafka UI)
  # ============================
  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    container_name: kafdrop
    restart: always
    ports:
      - "9001:9000"
    environment:
      KAFKA_BROKERCONNECT: kafka:9092
    depends_on:
      - kafka
    networks:
      - cdc-net
  hue:
    image: gethue/hue:latest
    container_name: hue
    ports:
      - "8888:8888"
    environment:
      - HUE_CONF_DIR=/usr/share/hue/desktop/conf
    volumes:
      - ./hue/hue.ini:/usr/share/hue/desktop/conf/hue.ini
    depends_on:
      - hive-server
      - hive-metastore
      - namenode
      - datanode
    networks:
      - cdc-net
    restart: unless-stopped



networks:
  cdc-net:
    driver: bridge

volumes:
  namenode_data:
  datanode_data:
  metastore_db:
  spark_app:
  spark_data:
